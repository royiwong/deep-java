https://www.jianshu.com/p/f4cca5ce055a  
https://blog.csdn.net/zolalad/article/details/11848739  

##  时间复杂度和空间复杂度
### 说明  
时间复杂度和空间复杂度来衡量评估一种算法的优劣，我们一般采用大O渐进表示法描述一个算法的时间复杂度。时间复杂度主要讨论的是算法执行的次数。时间复杂度和空间复杂度是用来评价算法效率高低的2个标准。  
其实这两个概念从字面意思上也能看出一二：  
- 时间复杂度：就是说执行算法需要消耗的时间长短，越快越好。比如你在电脑上打开计算器，如果一个普通的运算要消耗1分钟时间，那谁还会用它呢，还不如自己口算呢。  
- 空间复杂度：就是说执行当前算法需要消耗的存储空间大小，也是越少越好。本来计算机的存储资源就是有限的，如果你的算法总是需要耗费很大的存储空间，这样也会给机器带来很大的负担。  
### 时间复杂度的计算  
####  表示方法  
我们一般用“大O符号表示法”来表示时间复杂度：```T(n) = O(f(n))```  
n是影响复杂度变化的因子，f(n)是复杂度具体的算法。大O符号表示法并不是用于来真实代表算法的 执行时间的，它是用来表示代码执行时间的增长变化趋势的  
####  常见的时间复杂度量级  
- 常数阶```O(1)```  
- 线性阶```O(n)```  
- 对数阶```O(logN)```  
- 线性对数阶```O(nlogN)```  
- 平方阶```O(n²)```  
- 立方阶```O(n³)```  
- K次方阶```O(n^k)```   
- 指数阶```(2^n)```  
接下来再看一下不同的复杂度所对应的算法类型。  
####  常数阶O(1)
``` java
int a = 1;
int b = 2;
int c = 3;
```
我们假定每执行一行代码所需要消耗的时间为1个时间单位，那么以上3行代码就消耗了3个时间单位。那是不是这段代码的时间复杂度表示为O(n)呢 ？  
其实不是的，因为大O符号表示法并不是用于来真实代表算法的执行时间的，它是用来表示代码执行时间的增长变化趋势的。上面的算法并没有随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用O(1)来表示它的时间复杂度。  
#### 线性阶O(n)
``` java
for(i = 1; i <= n; i++) {
   j = i;
   j++;
}
```
看这段代码会执行多少次呢？  
第1行会执行1次，第2行和第3行会分别执行n次，总的执行时间也就是 2n + 1 次，那它的时间复杂度表示是 O(2n + 1) 吗？ No !  
还是那句话：“大O符号表示法并不是用于来真实代表算法的执行时间的，它是用来表示代码执行时间的增长变化趋势的”。所以它的时间复杂度其实是O(n)。  
###  对数阶O(logN)
``` java
int i = 1;
while(i < n) {
    i = i * 2;
}
```
可以看到每次循环的时候 i 都会乘2，那么总共循环的次数就是log2n，因此这个代码的时间复杂度为O(logn)。  
这儿有个问题，为什么明明应该是O(log2n）,却要写成O(logn)呢？  
其实这里的底数对于研究程序运行效率不重要，写代码时要考虑的是数据规模n对程序运行效率的影响，常数部分则忽略，同样的，如果不同时间复杂度的倍数关系为常数，那也可以近似认为两者为同一量级的时间复杂度。  
####  线性对数阶O(nlogN)
``` java 
for(m = 1; m < n; m++) {
    i = 1;
    while(i < n) {
        i = i * 2;
    }
}
```
线性对数阶O(nlogN) 其实非常容易理解，将时间复杂度为O(logn)的代码循环N遍的话，那么它的时间复杂度就是 n * O(logN)，也就是了O(nlogN)。  
####  平方阶O(n²)
``` java
for(x = 1; i <= n; x++){
   for(i = 1; i <= n; i++) {
       j = i;
       j++;
    }
}
```
把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 O(n²) 了。
####  立方阶O(n³)、K次方阶O(n^k)
参考上面的O(n²) 去理解就好了，O(n³)相当于三层n循环，其它的类似。


### 理论描述：
算法的时间复杂度，用来度量算法的运行时间，记作: T(n) = O(f(n))。它表示随着输入大小n的增大，算法执行需要的时间的
增长速度可以用 f(n) 来描述。其中，T(n)代表算法执行的时间，f(n)代表T(n)的上界，即当n > c (任意常数)，总有T(n) <= f(n)。  

如下图所示，假定一个函数的执行时间随着输入参数n的增加而线性增加，记为T(n) = n +2。当n = 2时，T(n=2) = 4，需要执行4此操作；
当n = 4时，T(n=4) = 6, 需要执行6次操作。算法执行次数（或耗时）随着参数增加而线性递增。    
   
假定现在有一个函数 f(n) = n², 满足n >= c时，总有f(n)>=T(n) ,则T(n)的时间复杂度可以表达为 T(n):=O(f(n))=O(n²)。  
实际上，我们可以我们只关注算法耗时的增长率，而通常忽略常数部分（常数增长率为0）。因此， T(n):=O(g(n))=O(n)  能更好的表达T(n)的时间复杂度（下图红色线）。

那实际如何操作呢？   
求解算法的时间复杂度的具体步骤是：   
1、找出算法中的基本语句：即算法中执行次数最多的那条语句，通常是最内层循环的循环体。  
2、计算基本语句的执行次数的数量级；  
3、用大Ο记号表示算法的时间性能。   
